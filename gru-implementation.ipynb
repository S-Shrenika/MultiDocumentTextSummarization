{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"id":"3BsovcWHTCW8","trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/news-summary/news_summary.csv\",encoding=\"iso-8859-1\")\ndata.head()","metadata":{"id":"87oy1YUrDv1B","executionInfo":{"status":"ok","timestamp":1617429805801,"user_tz":-330,"elapsed":1024,"user":{"displayName":"Soma Shrenika","photoUrl":"https://lh6.googleusercontent.com/-CuDisEOkyiY/AAAAAAAAAAI/AAAAAAAAV44/mVoBdmC5VOo/s64/photo.jpg","userId":"07044512319009107674"}},"outputId":"b68cb5e3-40f5-4977-e64d-0da933ad1fbb","trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"               author                  date  \\\n0        Chhavi Tyagi  03 Aug 2017,Thursday   \n1         Daisy Mowke  03 Aug 2017,Thursday   \n2      Arshiya Chopra  03 Aug 2017,Thursday   \n3       Sumedha Sehra  03 Aug 2017,Thursday   \n4  Aarushi Maheshwari  03 Aug 2017,Thursday   \n\n                                           headlines  \\\n0  Daman & Diu revokes mandatory Rakshabandhan in...   \n1  Malaika slams user who trolled her for 'divorc...   \n2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n3  Aaj aapne pakad liya: LeT man Dujana before be...   \n4  Hotel staff to get training to spot signs of s...   \n\n                                           read_more  \\\n0  http://www.hindustantimes.com/india-news/raksh...   \n1  http://www.hindustantimes.com/bollywood/malaik...   \n2  http://www.hindustantimes.com/patna/bihar-igim...   \n3  http://indiatoday.intoday.in/story/abu-dujana-...   \n4  http://indiatoday.intoday.in/story/sex-traffic...   \n\n                                                text  \\\n0  The Administration of Union Territory Daman an...   \n1  Malaika Arora slammed an Instagram user who tr...   \n2  The Indira Gandhi Institute of Medical Science...   \n3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n4  Hotels in Maharashtra will train their staff t...   \n\n                                               ctext  \n0  The Daman and Diu administration on Wednesday ...  \n1  From her special numbers to TV?appearances, Bo...  \n2  The Indira Gandhi Institute of Medical Science...  \n3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n4  Hotels in Mumbai and other Indian cities are t...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>date</th>\n      <th>headlines</th>\n      <th>read_more</th>\n      <th>text</th>\n      <th>ctext</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chhavi Tyagi</td>\n      <td>03 Aug 2017,Thursday</td>\n      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n      <td>The Administration of Union Territory Daman an...</td>\n      <td>The Daman and Diu administration on Wednesday ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Daisy Mowke</td>\n      <td>03 Aug 2017,Thursday</td>\n      <td>Malaika slams user who trolled her for 'divorc...</td>\n      <td>http://www.hindustantimes.com/bollywood/malaik...</td>\n      <td>Malaika Arora slammed an Instagram user who tr...</td>\n      <td>From her special numbers to TV?appearances, Bo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arshiya Chopra</td>\n      <td>03 Aug 2017,Thursday</td>\n      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n      <td>http://www.hindustantimes.com/patna/bihar-igim...</td>\n      <td>The Indira Gandhi Institute of Medical Science...</td>\n      <td>The Indira Gandhi Institute of Medical Science...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sumedha Sehra</td>\n      <td>03 Aug 2017,Thursday</td>\n      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n      <td>http://indiatoday.intoday.in/story/abu-dujana-...</td>\n      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Aarushi Maheshwari</td>\n      <td>03 Aug 2017,Thursday</td>\n      <td>Hotel staff to get training to spot signs of s...</td>\n      <td>http://indiatoday.intoday.in/story/sex-traffic...</td>\n      <td>Hotels in Maharashtra will train their staff t...</td>\n      <td>Hotels in Mumbai and other Indian cities are t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n\n                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n\n                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n\n                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n\n                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n\n                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n\n                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n\n                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n\n                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n\n                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n\n                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n\n                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n\n                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n\n                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n\n                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n\n                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n\n                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n\n                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n\n                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n\n                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n\n                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n\n                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n\n                           \"you're\": \"you are\", \"you've\": \"you have\"}","metadata":{"id":"zEwOonSKlmTx","trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download(\"stopwords\")\n\nimport re\nfrom nltk.corpus import stopwords\n\nstop_words = stopwords.words('english')\n\ndef preprocess(text):\n    text = text.lower() # lowercase\n    text = text.split() # convert have'nt -> have not\n    for i in range(len(text)):\n        word = text[i]\n        if word in contraction_mapping:\n            text[i] = contraction_mapping[word]\n    text = \" \".join(text)\n    text = text.split()\n    newtext = []\n    for word in text:\n        if word not in stop_words:\n            newtext.append(word)\n    text = \" \".join(newtext)\n    text = text.replace(\"'s\",'') # convert your's -> your\n    text = re.sub(r'\\(.*\\)','',text) # remove (words)\n    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n    text = re.sub(r'\\.',' . ',text)\n    return text\n\nsample = \"(hello) hi there .man tiger caller who's that isn't it ? WALL-E\"\nprint(preprocess(sample))","metadata":{"id":"hgttCkv2EJDt","executionInfo":{"status":"ok","timestamp":1617429826867,"user_tz":-330,"elapsed":2395,"user":{"displayName":"Soma Shrenika","photoUrl":"https://lh6.googleusercontent.com/-CuDisEOkyiY/AAAAAAAAAAI/AAAAAAAAV44/mVoBdmC5VOo/s64/photo.jpg","userId":"07044512319009107674"}},"outputId":"34f86198-f610-4243-ffab-8369769a8aac","trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n hi  . man tiger caller  walle\n","output_type":"stream"}]},{"cell_type":"code","source":"data['headlines'] = data['headlines'].apply(lambda x:preprocess(x))\ndata['text'] = data['text'].apply(lambda x:preprocess(x))\nprint(data['headlines'][20],data['text'][20])","metadata":{"id":"14uXn9nWEYS5","executionInfo":{"status":"ok","timestamp":1617429831545,"user_tz":-330,"elapsed":1561,"user":{"displayName":"Soma Shrenika","photoUrl":"https://lh6.googleusercontent.com/-CuDisEOkyiY/AAAAAAAAAAI/AAAAAAAAV44/mVoBdmC5VOo/s64/photo.jpg","userId":"07044512319009107674"}},"outputId":"0c852329-771f-4bb2-e77a-70fc7fc2adfd","trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"baby pregnant malformed twin born maharashtra newborn boy maharashtra thane found pregnant halfformed twin feeding boy blood supply .  doctors said rare condition called fetus fetu less 200 cases recorded till date .  doctors successfully operated remove 7cm fetus weighed 150 gram . \n","output_type":"stream"}]},{"cell_type":"code","source":"x = data['text']\ny = data['headlines']\nprint(x[50],y[50],sep='\\n')","metadata":{"id":"2julEYdBoEhm","executionInfo":{"status":"ok","timestamp":1617429845365,"user_tz":-330,"elapsed":941,"user":{"displayName":"Soma Shrenika","photoUrl":"https://lh6.googleusercontent.com/-CuDisEOkyiY/AAAAAAAAAAI/AAAAAAAAV44/mVoBdmC5VOo/s64/photo.jpg","userId":"07044512319009107674"}},"outputId":"2feb78bb-6ef3-4562-df0c-919c8ead4a56","trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"mumbai court convicted 15 somali pirates 7 years imprisonment 2011 case .  pirates found guilty attempt murder kidnapping taking 22 people hostage board commercial ship thailand .  one four cases registered 120 somali pirates holding 91 people different countries hostage . \nmumbai court convicts 15 somali pirates 2011 case\n","output_type":"stream"}]},{"cell_type":"code","source":"import unicodedata\nimport string\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"8sS4W1tzoLfq","trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"SOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","metadata":{"id":"T1_igQgBoP9S","trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def readLangs(text, summary, reverse=False):\n    print(\"Reading lines...\")\n    \n    # Split every line into pairs and normalize\n    pairs = [[text[i],summary[i]] for i in range(len(text))]\n\n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(summary)\n        output_lang = Lang(text)\n    else:\n        input_lang = Lang(text)\n        output_lang = Lang(summary)\n\n    return input_lang, output_lang, pairs","metadata":{"id":"cUERHa55oToI","trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def prepareData(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs","metadata":{"id":"iJpcstO2oV4B","trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"input_lang, output_lang, pairs = prepareData( x, y , False)\nprint(random.choice(pairs))","metadata":{"id":"FHyzwCSCoYEI","executionInfo":{"status":"ok","timestamp":1617429866372,"user_tz":-330,"elapsed":960,"user":{"displayName":"Soma Shrenika","photoUrl":"https://lh6.googleusercontent.com/-CuDisEOkyiY/AAAAAAAAAAI/AAAAAAAAV44/mVoBdmC5VOo/s64/photo.jpg","userId":"07044512319009107674"}},"outputId":"41b9969e-11a6-4565-8a28-2e346155db46","trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Reading lines...\nRead 4514 sentence pairs\nCounting words...\nCounted words:\n0       administration union territory daman diu revok...\n1       malaika arora slammed instagram user trolled d...\n2       indira gandhi institute medical sciences  patn...\n3       lashkaretaiba kashmir commander abu dujana kil...\n4       hotels maharashtra train staff spot signs sex ...\n                              ...                        \n4509    fruit juice concentrate maker rasna eyeing rev...\n4510    former indian cricketer sachin tendulkar atten...\n4511    aamir khan talking reality shows television fe...\n4512    maharashtra government initiated inquiry 83yea...\n4513    least 400 languages half languages spoken indi...\nName: text, Length: 4514, dtype: object 20996\n0       daman  diu revokes mandatory rakshabandhan off...\n1           malaika slams user trolled divorcing rich man\n2                   virgin corrected unmarried igims form\n3              aaj aapne pakad liya let man dujana killed\n4       hotel staff get training spot signs sex traffi...\n                              ...                        \n4509    rasna seeking 250 cr revenue snack category ch...\n4510      sachin attends rajya sabha questions attendance\n4511               rob childhood aamir kids reality shows\n4512    asha bhosle gets 53000 power bill unused bungalow\n4513            half india languages may die 50yrs survey\nName: headlines, Length: 4514, dtype: object 9083\n['thirtyfiveyearold roger federer become oldest men singles wimbledon finalist since 1974 defeating czech tennis player tomas berdych 76 76 64 semifinal friday .  federer dropped single set wimbledon 2017 reached career 11th wimbledon final .  federer face firsttime wimbledon finalist marin cilic final sunday . ', 'roger federer becomes oldest wimbledon finalist 43 years']\n","output_type":"stream"}]},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)\nclass DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        output = self.embedding(input).view(1, 1, -1)\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)\nMAX_LENGTH = 90\nclass AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n        super(AttnDecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.dropout_p = dropout_p\n        self.max_length = max_length\n\n        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n        self.dropout = nn.Dropout(self.dropout_p)\n        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n        self.out = nn.Linear(self.hidden_size, self.output_size)\n\n    def forward(self, input, hidden, encoder_outputs):\n        embedded = self.embedding(input).view(1, 1, -1)\n        embedded = self.dropout(embedded)\n\n        attn_weights = F.softmax(\n            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n                                 encoder_outputs.unsqueeze(0))\n\n        output = torch.cat((embedded[0], attn_applied[0]), 1)\n        output = self.attn_combine(output).unsqueeze(0)\n\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n\n        output = F.log_softmax(self.out(output[0]), dim=1)\n        return output, hidden, attn_weights\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","metadata":{"id":"G-FEVkSNoaRw","trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)","metadata":{"id":"3UyJagTSoigO","trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"teacher_forcing_ratio = 0.5\ndef train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n    encoder_hidden = encoder.initHidden()\n\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    loss = 0\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(\n            input_tensor[ei], encoder_hidden)\n        encoder_outputs[ei] = encoder_output[0, 0]\n\n    decoder_input = torch.tensor([[SOS_token]], device=device)\n\n    decoder_hidden = encoder_hidden\n\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        # Teacher forcing: Feed the target as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]  # Teacher forcing\n\n    else:\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n\n            loss += criterion(decoder_output, target_tensor[di])\n            if decoder_input.item() == EOS_token:\n                break\n\n    loss.backward()\n\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return loss.item() / target_length","metadata":{"id":"1Y6QNoj4oqIt","trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import time\nimport math\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"id":"Rc5AH-61oxg2","trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","metadata":{"id":"vDy0Hr9Co3J1","trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    print(\"Training....\")\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n    training_pairs = [tensorsFromPair(random.choice(pairs))\n                      for i in range(n_iters)]\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        if iter% 1000 == 0:\n            print(iter,\"/\",n_iters + 1)\n        training_pair = training_pairs[iter - 1]\n        input_tensor = training_pair[0]\n        target_tensor = training_pair[1]\n\n        loss = train(input_tensor, target_tensor, encoder,\n                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n                                         iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    return showPlot(plot_losses)\ndef evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n        input_length = input_tensor.size()[0]\n        encoder_hidden = encoder.initHidden()\n\n        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n        for ei in range(input_length):\n            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n                                                     encoder_hidden)\n            encoder_outputs[ei] += encoder_output[0, 0]\n\n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoder_hidden\n\n        decoded_words = []\n        decoder_attentions = torch.zeros(max_length, max_length)\n\n        for di in range(max_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            decoder_attentions[di] = decoder_attention.data\n            topv, topi = decoder_output.data.topk(1)\n            if topi.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            else:\n                decoded_words.append(output_lang.index2word[topi.item()])\n\n            decoder_input = topi.squeeze().detach()\n\n        return decoded_words, decoder_attentions[:di + 1]\ndef evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, attentions = evaluate(encoder, decoder, pair[0])\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","metadata":{"id":"yawaB6uCo5ZN","trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"hidden_size = 512\nencoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\nattn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\niterations=150000\ntrainIters(encoder1, attn_decoder1, iterations, print_every=(iterations//15))","metadata":{"id":"heoo9v0fo-ck","executionInfo":{"status":"ok","timestamp":1617436628593,"user_tz":-330,"elapsed":6192825,"user":{"displayName":"Soma Shrenika","photoUrl":"https://lh6.googleusercontent.com/-CuDisEOkyiY/AAAAAAAAAAI/AAAAAAAAV44/mVoBdmC5VOo/s64/photo.jpg","userId":"07044512319009107674"}},"outputId":"1367e1c6-eac6-4307-ec64-064d419bd3b9","trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Training....\n1000 / 150001\n2000 / 150001\n3000 / 150001\n4000 / 150001\n5000 / 150001\n6000 / 150001\n7000 / 150001\n8000 / 150001\n9000 / 150001\n10000 / 150001\n8m 26s (- 118m 11s) (10000 6%) 6.5017\n11000 / 150001\n12000 / 150001\n13000 / 150001\n14000 / 150001\n15000 / 150001\n16000 / 150001\n17000 / 150001\n18000 / 150001\n19000 / 150001\n20000 / 150001\n16m 51s (- 109m 37s) (20000 13%) 5.8372\n21000 / 150001\n22000 / 150001\n23000 / 150001\n24000 / 150001\n25000 / 150001\n26000 / 150001\n27000 / 150001\n28000 / 150001\n29000 / 150001\n30000 / 150001\n25m 27s (- 101m 51s) (30000 20%) 3.9988\n31000 / 150001\n32000 / 150001\n33000 / 150001\n34000 / 150001\n35000 / 150001\n36000 / 150001\n37000 / 150001\n38000 / 150001\n39000 / 150001\n40000 / 150001\n34m 10s (- 93m 59s) (40000 26%) 2.2945\n41000 / 150001\n42000 / 150001\n43000 / 150001\n44000 / 150001\n45000 / 150001\n46000 / 150001\n47000 / 150001\n48000 / 150001\n49000 / 150001\n50000 / 150001\n42m 52s (- 85m 45s) (50000 33%) 1.2305\n51000 / 150001\n52000 / 150001\n53000 / 150001\n54000 / 150001\n55000 / 150001\n56000 / 150001\n57000 / 150001\n58000 / 150001\n59000 / 150001\n60000 / 150001\n51m 37s (- 77m 25s) (60000 40%) 0.6856\n61000 / 150001\n62000 / 150001\n63000 / 150001\n64000 / 150001\n65000 / 150001\n66000 / 150001\n67000 / 150001\n68000 / 150001\n69000 / 150001\n70000 / 150001\n60m 22s (- 68m 59s) (70000 46%) 0.3709\n71000 / 150001\n72000 / 150001\n73000 / 150001\n74000 / 150001\n75000 / 150001\n76000 / 150001\n77000 / 150001\n78000 / 150001\n79000 / 150001\n80000 / 150001\n69m 2s (- 60m 24s) (80000 53%) 0.2044\n81000 / 150001\n82000 / 150001\n83000 / 150001\n84000 / 150001\n85000 / 150001\n86000 / 150001\n87000 / 150001\n88000 / 150001\n89000 / 150001\n90000 / 150001\n77m 39s (- 51m 46s) (90000 60%) 0.0996\n91000 / 150001\n92000 / 150001\n93000 / 150001\n94000 / 150001\n95000 / 150001\n96000 / 150001\n97000 / 150001\n98000 / 150001\n99000 / 150001\n100000 / 150001\n86m 14s (- 43m 7s) (100000 66%) 0.0456\n101000 / 150001\n102000 / 150001\n103000 / 150001\n104000 / 150001\n105000 / 150001\n106000 / 150001\n107000 / 150001\n108000 / 150001\n109000 / 150001\n110000 / 150001\n94m 50s (- 34m 29s) (110000 73%) 0.0270\n111000 / 150001\n112000 / 150001\n113000 / 150001\n114000 / 150001\n115000 / 150001\n116000 / 150001\n117000 / 150001\n118000 / 150001\n119000 / 150001\n120000 / 150001\n103m 26s (- 25m 51s) (120000 80%) 0.0171\n121000 / 150001\n122000 / 150001\n123000 / 150001\n124000 / 150001\n125000 / 150001\n126000 / 150001\n127000 / 150001\n128000 / 150001\n129000 / 150001\n130000 / 150001\n112m 2s (- 17m 14s) (130000 86%) 0.0143\n131000 / 150001\n132000 / 150001\n133000 / 150001\n134000 / 150001\n135000 / 150001\n136000 / 150001\n137000 / 150001\n138000 / 150001\n139000 / 150001\n140000 / 150001\n120m 36s (- 8m 36s) (140000 93%) 0.0111\n141000 / 150001\n142000 / 150001\n143000 / 150001\n144000 / 150001\n145000 / 150001\n146000 / 150001\n147000 / 150001\n148000 / 150001\n149000 / 150001\n150000 / 150001\n129m 12s (- 0m 0s) (150000 100%) 0.0099\n","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu\n\ndef BLEU(encoder, attention_decoder, n_examples):\n    total_score = 0\n    evaluate_pairs = [random.choice(pairs) for i in range(n_examples)]\n    for pair in evaluate_pairs:\n        input_sentence = pair[0]\n        target_words = [pair[1]]\n        output_words, _ = evaluate(encoder, attention_decoder, input_sentence)\n        output_words = output_words\n        score = sentence_bleu(target_words, output_words)\n        total_score += score\n    average_BLEU = total_score/len(pairs)\n    return average_BLEU","metadata":{"id":"B4P69MJBpCyr","trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"BLEUScore = BLEU(encoder1, attn_decoder1, 5000)","metadata":{"id":"--voIv-WtC1w","executionInfo":{"status":"ok","timestamp":1617436701445,"user_tz":-330,"elapsed":67803,"user":{"displayName":"Soma Shrenika","photoUrl":"https://lh6.googleusercontent.com/-CuDisEOkyiY/AAAAAAAAAAI/AAAAAAAAV44/mVoBdmC5VOo/s64/photo.jpg","userId":"07044512319009107674"}},"outputId":"f013bda6-d207-4fb4-f7a0-782d65be0423","trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluateRandomly(encoder1, attn_decoder1)","metadata":{"id":"ARlJMGmH0bTx","executionInfo":{"status":"ok","timestamp":1617436994909,"user_tz":-330,"elapsed":1170,"user":{"displayName":"Soma Shrenika","photoUrl":"https://lh6.googleusercontent.com/-CuDisEOkyiY/AAAAAAAAAAI/AAAAAAAAV44/mVoBdmC5VOo/s64/photo.jpg","userId":"07044512319009107674"}},"outputId":"e643fedc-835f-4df9-d885-2898dd559da5","trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"> usbased study found brain cognitive abilities may significantly reduced mere presence smartphone even switched off .  series tests requiring concentration participants phones another room outperformed phones desk also kept phones pocket bag researchers said . \n= smartphone within reach reduces brain power study\n< smartphone within reach reduces brain power study <EOS>\n\n> union minister ravi shankar prasad friday said though muslims vote bjp bjp government given proper sanctity .  we got 13 chief ministers own .  ruling country .  victimised muslim gentleman working industry service dismissed them asked . \n= muslims vote us gave sanctity prasad\n< muslims vote us gave sanctity prasad <EOS>\n\n> 22000 people evacuated saturday fire broke one stages tomorrowland unite music festival barcelona spain .  believed fire could triggered firework display part show .  firefighters managed extinguish flame injuries reported said organisers . \n= 22000 people evacuated fire spain music festival\n< 22000 people evacuated fire spain music festival <EOS>\n\n> pope francis slammed media organisations focus scandals promote fake news said people consume content coprophagic faeceseaters .  added spreading disinformation probably greatest damage media do .  earlier us president barack obama slammed online misinformation threat democratic institutions . \n= pope francis compares reading fake news eating poop\n< pope francis compares reading fake news eating poop <EOS>\n\n> official james bond twitter handle announced november 8 2019 release date new film franchise titled bond 25 .  film written neal purvis robert wade produced michael g .  wilson barbara broccoli .  daniel craig reportedly return character james bond film . \n= release date new james bond film bond 25 announced\n< release date new james bond film bond 25 announced <EOS>\n\n> outgoing uttar pradesh cm akhilesh yadav sunday said our struggle continue adding samajwadi party party ideology .  told party workers you reach people strengthen party again .  samajwadi party devise new strategy meeting mlas party candidates added . \n= struggle continue akhilesh yadav\n< struggle continue akhilesh yadav <EOS>\n\n> supreme court questioned centre secrecy demonetisation move asking when made policy demonetisation confidential sc hearing plea seeking explanation putting nation great difficulties arguing centre ag rohatgi said the government taken necessary steps ease inconveniences . \n= demonetisation policy confidential sc asks centre\n< demonetisation policy confidential sc asks centre <EOS>\n\n> singer himesh reshammiya wife komal married 22 years finally got divorce finalised wednesday .  december 2016 himesh komal confirmed media seeking legal separation .  himesh earlier said komal amicably decided part ways .  .  . komal always remain part family . \n= himesh reshammiya divorce wife 22 years finalised\n< himesh reshammiya divorce wife 22 years finalised <EOS>\n\n> delhi judge noted difference punishment killing cows people sentencing man causing death rash driving .  the sentence killing cow five seven 14 years different states sentence causing death human rash negligent driving two years said . \n= 14 yrs jail killing cow 2 yrs killing people judge\n< 14 yrs jail killing cow 2 yrs killing people judge <EOS>\n\n> man arrested thursday along accomplice stabbing 21yearold woman najafgarh area delhi according reports .  accused friend victim brother claimed love victim .  rejected proposal relationship decided kill her told police . \n= man arrested stabbing woman rejecting proposal\n< man arrested stabbing woman rejecting proposal <EOS>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"sgSq_FJ00gF_"},"execution_count":null,"outputs":[]}]}